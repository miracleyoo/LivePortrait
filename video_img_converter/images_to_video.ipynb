{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video(image_paths, output_video_path, fps=30):\n",
    "    # Read the first image to get the dimensions\n",
    "    frame = cv2.imread(image_paths[0])\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        video.write(cv2.imread(image_path))\n",
    "\n",
    "    # Release the video writer object\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver1 Video Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atalie', 'keli', 'matt', 'ning']\n"
     ]
    }
   ],
   "source": [
    "# Load the image lists to generate videos\n",
    "image_list_record_root = '/prj/qct/mmrd-cv/wonderland_data/3DFR_Data_wrap4d/Pair_man/PAC/meta/train'\n",
    "image_root = '/prj/qct/mmrd-cv/wonderland_data/3DFR_Data/3dMD/PAC'\n",
    "out_root = '/prj/qct/mmrd-cv/wonderland_data/3DFR_Data/3dMD/PAC/live-portrait-data/processed_videos'\n",
    "image_lists_records_out_path = '/prj/qct/mmrd-cv/wonderland_data/3DFR_Data/3dMD/PAC/live-portrait-data/image_lists_records.pkl'\n",
    "\n",
    "# subject_names = ['atalie', 'keli', 'matt', 'ning']\n",
    "image_lists_record_files = [\n",
    "    'data_parsed_List_atalie_man_process_list_train.csv',\n",
    "    'data_parsed_List_keli_man_process_list_train.csv',\n",
    "    'data_parsed_List_matt_man_process_list_train.csv',\n",
    "    'data_parsed_List_ning_man_process_list_train.csv'\n",
    "]\n",
    "# get the subject names using regex\n",
    "subject_names = [re.search(r'data_parsed_List_(.*)_man_process_list_train.csv', f).group(1) for f in image_lists_record_files]\n",
    "print(subject_names)\n",
    "\n",
    "image_lists_record_files = [osp.join(image_list_record_root, p) for p in image_lists_record_files]\n",
    "image_lists_records = []\n",
    "\n",
    "def add_unified_suffix(path):\n",
    "    root, name = osp.split(path)\n",
    "    stem, ext = osp.splitext(name)\n",
    "    if not stem.endswith('05_C'):\n",
    "        stem += '.05_C'\n",
    "    return osp.join(image_root, root, stem+ext)\n",
    "\n",
    "for f in image_lists_record_files:\n",
    "    img_list = pd.read_csv(f)['tar_bg'].tolist()\n",
    "    img_list = [add_unified_suffix(p) for p in img_list]\n",
    "    image_lists_records.append(img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver2 Video Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject5_cap', 'subject5_tied_hair', 'subject25_cap', 'subject25_tied_hair']\n"
     ]
    }
   ],
   "source": [
    "# Load the image lists to generate videos\n",
    "image_list_record_root = '/mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose/meta'\n",
    "image_root = '/mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose'\n",
    "out_root = '/mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose/processed_videos_ver2'\n",
    "image_lists_records_out_path = '/mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose/image_lists_records.pkl'\n",
    "\n",
    "subject_names = ['atalie', 'keli', 'matt', 'ning']\n",
    "image_lists_record_files = [\n",
    "    'data_parsed_List_subject5_cap_man_process_list_train.csv',\n",
    "    'data_parsed_List_subject5_tied_hair_man_process_list_train.csv',\n",
    "    'data_parsed_List_subject25_cap_man_process_list_train.csv',\n",
    "    'data_parsed_List_subject25_tied_hair_man_process_list_train.csv'\n",
    "]\n",
    "# get the subject names using regex\n",
    "subject_names = [re.search(r'data_parsed_List_(.*)_man_process_list_train.csv', f).group(1) for f in image_lists_record_files]\n",
    "print(subject_names)\n",
    "\n",
    "image_lists_record_files = [osp.join(image_list_record_root, p) for p in image_lists_record_files]\n",
    "image_lists_records = []\n",
    "\n",
    "def add_unified_suffix(path):\n",
    "    return osp.join(image_root, path+'.syn.png')\n",
    "\n",
    "for f in image_lists_record_files:\n",
    "    img_list = pd.read_csv(f)['tar'].tolist()\n",
    "    img_list = [add_unified_suffix(p) for p in img_list]\n",
    "    image_lists_records.append(img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Check file existance status\n",
    "for il in image_lists_records:\n",
    "    print(osp.exists(il[0]), osp.exists(il[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing:  /mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose/processed_videos_ver2/subject5_cap.mp4\n",
      "Now processing:  /mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose/processed_videos_ver2/subject5_tied_hair.mp4\n",
      "Now processing:  /mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose/processed_videos_ver2/subject25_cap.mp4\n",
      "Now processing:  /mnt/QPFA-LV/dataset/LightCage_Process_MV_Data/PAC_Add_Nose/processed_videos_ver2/subject25_tied_hair.mp4\n"
     ]
    }
   ],
   "source": [
    "# Generate Videos\n",
    "for idx, img_list in enumerate(image_lists_records):\n",
    "    subj_name = subject_names[idx]\n",
    "    out_video_path = osp.join(out_root, f'{subj_name}.mp4')\n",
    "    print(\"Now processing: \", out_video_path)\n",
    "    \n",
    "    # Generate video from images\n",
    "    images_to_video(img_list, out_video_path, fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filenames\n",
    "import pickle as pkl\n",
    "image_lists_records_out_path = '/prj/qct/mmrd-cv/wonderland_data/3DFR_Data/3dMD/PAC/live-portrait-data/image_lists_records.pkl'\n",
    "with open(image_lists_records_out_path, 'wb') as f:\n",
    "    pkl.dump(image_lists_records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LivePortrait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
